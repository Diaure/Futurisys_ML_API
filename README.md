---
title: Futurisys ML API
emoji: ğŸš€
colorFrom: blue
colorTo: green
sdk: docker
pinned: false
---


# Futurisys â€“ DÃ©ploiement dâ€™un modÃ¨le de Machine Learning via API

## Contexte
**Futurisys** est une entreprise innovante souhaitant rendre ses modÃ¨les de machine learning
opÃ©rationnels et accessibles via une API performante.

Ce projet correspond Ã  un **Proof of Concept (POC)** visant Ã  dÃ©ployer un modÃ¨le de machine
learning en production en appliquant les bonnes pratiques dâ€™ingÃ©nierie logicielle: versionnage, tests, base de donnÃ©es et automatisation.


## Objectifs du projet
- DÃ©ployer un modÃ¨le de machine learning via une API REST
- Rendre le modÃ¨le accessible de maniÃ¨re fiable et documentÃ©e
- Mettre en place une architecture maintenable et Ã©volutive
- Appliquer un workflow Git professionnel
- PrÃ©parer une base solide pour un dÃ©ploiement en production


## PÃ©rimÃ¨tre fonctionnel
Le projet inclut:
- Une API dÃ©veloppÃ©e avec **FastAPI**
- Lâ€™exposition dâ€™un modÃ¨le de machine learning via des endpoints REST
- Une base de donnÃ©es **PostgreSQL** pour stocker les entrÃ©es/sorties du modÃ¨le
- Des tests unitaires et fonctionnels avec **Pytest**
- Un pipeline **CI/CD** pour automatiser les tests et le dÃ©ploiement
- Une documentation technique claire

## CI/CD et DÃ©ploiement

Ce projet met en Å“uvre une approche CI/CD complÃ¨te, sÃ©parant:
- lâ€™intÃ©gration continue (**CI**): garantir la qualitÃ© du code
- le dÃ©ploiement continu (**CD**): rendre lâ€™API accessible publiquement

### `IntÃ©gration Continue (CI) â€“ GitHub Actions`

Lâ€™intÃ©gration continue est assurÃ©e via GitHub Actions.

Ã€ chaque **push** sur les branches de travail et Ã  chaque **pull request** vers **`develop`**,
le pipeline exÃ©cute automatiquement les Ã©tapes suivantes:
- installation dâ€™un environnement Python 3.11 isolÃ©
- installation des dÃ©pendances dÃ©finies dans le projet
- exÃ©cution des tests automatisÃ©s avec Pytest

Lâ€™objectif est de:
- vÃ©rifier que le projet est installable
- garantir que lâ€™API dÃ©marre correctement
- valider le chargement du modÃ¨le et le endpoint /*`predict`*
- Ã©viter toute rÃ©gression avant fusion vers **`develop`**.

### `DÃ©ploiement Continu (CD) â€“ Hugging Face Spaces`

Le dÃ©ploiement de lâ€™API est rÃ©alisÃ© sur Hugging Face Spaces qui permet:

- dâ€™hÃ©berger gratuitement des applications ML
- de dÃ©ployer une API DockerisÃ©e
- dâ€™exposer un service accessible publiquement sans gÃ©rer de serveur

Dans ce projet, Hugging Face est utilisÃ© comme plateforme de dÃ©monstration et de mise Ã  disposition de lâ€™API.

Le dÃ©ploiement repose sur un Dockerfile, qui dÃ©finit:
- lâ€™image Python utilisÃ©e (Python 3.11)
- lâ€™installation des dÃ©pendances
- le lancement de lâ€™API avec Uvicorn

Il garantit la reproductibilitÃ© de l'environnement lors de l'exÃ©cution de l'API.

A noter que les ***fichiers binaires*** ne sont pas stochÃ©s dans le dÃ©pÃ´t GiHub principal pour les raisons suivantes:
- Hugging Face bloque les push Git contenant des fichiers binaires lourds
- Git nâ€™est pas conÃ§u pour versionner des artefacts ML volumineux.

Pour contourner la situation, dans le projet, les artefacts sont stockÃ©s dans un Space Hugging Face dÃ©diÃ©, sÃ©parÃ© du code. Lors du dÃ©marrage de lAPI:
- le code tÃ©lÃ©charge dynamiquement les artefacts via huggingface_hub
- lâ€™API peut dÃ©marrer mÃªme si les fichiers ne sont pas prÃ©sents localement


### `Lancer lâ€™API en local`

Lâ€™API est dÃ©ployÃ©e publiquement sur Hugging Face Spaces.

- URL de lâ€™API :
https://diaure-futurisys-ml-api.hf.space
- Documentation interactive (Swagger UI):
https://diaure-futurisys-ml-api.hf.space/docs. Ele permet de:
  - visualiser les endpoints
  - tester directement lâ€™endpoint `/predict`
  - voir les schÃ©mas dâ€™entrÃ©e et de sortie.

### `Endpoint principal`
`POST /predict`

Cet endpoint reÃ§oit les caractÃ©ristiques dâ€™un employÃ© et retourne:

- une prÃ©diction lisible ("Reste" ou "Part")
- la probabilitÃ© associÃ©e au dÃ©part

Exemple de rÃ©ponse:
```json
{
  "Prediction": "Part",
  "Probabilite_depart": 0.795678996
}
```
Les donnÃ©es dâ€™entrÃ©e sont validÃ©es automatiquement avant lâ€™appel au modÃ¨le,
garantissant la cohÃ©rence avec les variables utilisÃ©es lors de lâ€™entraÃ®nement.

### `Documentation des endpoints`

Lâ€™API expose un endpoint principal de prÃ©diction.

**POST /predict**
  - Description : retourne une prÃ©diction de dÃ©part dâ€™un employÃ©
  - Validation des donnÃ©es: Pydantic
  - RÃ©ponses possibles:
    - 200: prÃ©diction valide
    - 422: donnÃ©es invalides

## Base de donnÃ©es et traÃ§abilitÃ© des prÃ©dictions
### `Objectifs`

Lâ€™intÃ©gration dâ€™une base de donnÃ©es PostgreSQL permet dâ€™inscrire le projet dans une logique MLOps et de rÃ©pondre Ã  plusieurs objectifs clÃ©s:
- assurer la traÃ§abilitÃ© complÃ¨te des prÃ©dictions du modÃ¨le
- conserver lâ€™historique des donnÃ©es dâ€™entrÃ©e utilisateur
- stocker les rÃ©sultats de prÃ©diction (label, probabilitÃ©, version du modÃ¨le)
- prÃ©parer une architecture compatible avec un dÃ©ploiement en production.

### `MÃ©thodologie utilisÃ©e`
- **PostgreSQL** a Ã©tÃ© retenu pour:
  - sa robustesse et sa fiabilitÃ©
  - sa compatibilitÃ© native avec SQLAlchemy
  - son usage courant en environnement professionnel

- **SQLAlchemy** est utilisÃ© comme couche dâ€™abstraction:
  - gestion centralisÃ©e de la connexion Ã  la base
  - cohÃ©rence entre le schÃ©ma Python et la base SQL

Les identifiants de connexion sont stockÃ©s dans des variables dâ€™environnement (`.env`) afin dâ€™Ã©viter toute exposition de secrets dans le dÃ©pÃ´t Git.

### `ModÃ©lisation de la base de donnÃ©es`
La base de donnÃ©es repose sur trois tables distinctes, chacune ayant un rÃ´le prÃ©cis.
1. `employees_dataset - Dataset de rÃ©fÃ©rence`
Il contient le dataset final nettoyÃ© et prÃ©parÃ© lors de l'entraÃ®nement du modÃ¨le en incluant l'ensemble des **32 deatures** du modÃ¨le. Il sert de:
  - rÃ©fÃ©rence de schÃ©ma
  - source de validation
  - base documentaire du modÃ¨le

C'est une table qui n'est jamais alimentÃ©e par l'utilisateur.

```python
load_dotenv()

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
csv_path = os.path.join(BASE_DIR, "dataset_final.csv")

df = pd.read_csv(csv_path, encoding="latin-1")

DB_USER = os.getenv("DB_USER")
DB_PASSWORD = os.getenv("DB_PASSWORD")
DB_HOST = os.getenv("DB_HOST")
DB_PORT = os.getenv("DB_PORT")
DB_NAME = os.getenv("DB_NAME")

DATABASE_URL = (f"postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}"f"@{DB_HOST}:{DB_PORT}/{DB_NAME}")

engine = create_engine(DATABASE_URL)

df.to_sql("employees_dataset", engine, if_exists="replace", index=False)
```

2. `inputs - EntrÃ©es utilisateur`
  - Enregistre chaque requÃªte utilisateur envoyÃ©e Ã  l'endpoint `/predict`
  - Contient exactement les features attendues par le modÃ¨le
  - Structure strictement alignÃ©e avec le schÃ©ma Pydandic(`EmployeeFeatures`)
  - Permet:
    - l'audit des predictions
    - l'analyse Ã  posteriori
    - la reproductibilitÃ© des rÃ©sultats.
```python
class Input(Base):
    __tablename__ = "inputs"

    id = Column(Integer, primary_key=True, index=True)
    genre = Column(String)
    statut_marital = Column(String)
    departement = Column(String)
    poste = Column(String)
```

3. `predictions - RÃ©sultats du modÃ¨le`
  - Continet:
    - le label de prÃ©diction
    - la probabilitÃ© associÃ©e
  - ReliÃ©e Ã  `inputs` via une clÃ© Ã©trangÃ¨re
  - Garantit une trÃ§abilitÃ© complÃ¨te.
```python
class Predictions(Base):
    __tablename__ = "predictions"
    id = Column(Integer, primary_key=True, index=True)
    input_id = Column(Integer, ForeignKey("inputs.id"))

    prediction_label = Column(String)
    prediction_proba = Column(Float)
    model_version = Column(String)
```

### `Interaction API <> Base de donnÃ©es`
Lors dâ€™un appel Ã  lâ€™endpoint `POST /predict`:
- les donnÃ©es utilisateur sont validÃ©es via **Pydantic**
- les entrÃ©es sont enregistrÃ©es dans la table **inputs**
- le modÃ¨le est exÃ©cutÃ©
- la prÃ©diction est enregistrÃ©e dans la table **predictions**
- la rÃ©ponse est retournÃ©e Ã  lâ€™utilisateur.

## Stack technique
- **Langage**: Python
- **API**: FastAPI
- **Machine Learning**: scikit-learn
- **Base de donnÃ©es**: PostgreSQL
- **Tests**: Pytest, pytest-cov
- **CI/CD**: GitHub Actions
- **Versionnage**: Git / GitHub


## Structure du projet
```text
futurisys_ml-api/
â”œâ”€â”€ github/workflows
â”‚   â”œâ”€â”€ ci.yml       # Description des Ã©vÃ¨nement dÃ©clenchants des tests
â”œâ”€â”€ app/             # Code applicatif principal
â”‚   â”œâ”€â”€ database.py  # Point de connexion Ã  la base PostgreSQL
â”‚   â”œâ”€â”€ main.py      # Point dâ€™entrÃ©e de lâ€™API
â”‚   â”œâ”€â”€ model.py     # DÃ©finition des tables de la database
â”‚   â”œâ”€â”€ predict.py   # Application du modÃ¨le
â”‚   â”œâ”€â”€ schemas.py   # Validation des donnÃ©es (Pydantic)
â”‚   â”€â”€ model/                            # Elements du modÃ¨le
â”‚   â”œâ”€â”€ mapping_classes.json             # Correspondances des classes
â”‚   â”œâ”€â”€ modele_final_xgb.joblib          # ModÃ¨le final avec hyperparamÃ¨tres
â”‚   â”œâ”€â”€ preprocesseur_fitted.joblib      # Pipeline entrainÃ©
|
â”œâ”€â”€ scripts/                   # Scripts bd (BD, donnÃ©es)
â”‚   â”œâ”€â”€ create_tables.py       # CrÃ©aton des tables dÃ©finies dans model.py
â”‚   â”œâ”€â”€ dataset_final.csv      # Data final
â”‚   â”œâ”€â”€ insert_dataset.py      # Code chargement de la table dataset_final
â”œâ”€â”€ tests/               # Tests unitaires, fonctionnels
â”‚   â”œâ”€â”€ test_api.py      # Test automatisÃ© de l'API via Pytest
|
â”œâ”€â”€ .env             # Stockage des variables sensibles et de configuration
â”œâ”€â”€ .gitignore       # Nettoyage du dÃ©pÃ´t
â”œâ”€â”€ pyproject.toml   # Librairies des modules entrainement ML
â”œâ”€â”€ README.md        # PrÃ©sentation du projet
â””â”€â”€ requirements.txt # Librairies des modules dispensables API
```
