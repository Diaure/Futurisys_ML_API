---
title: Futurisys ML API
emoji: ğŸš€
colorFrom: blue
colorTo: green
sdk: docker
pinned: false
---


# Futurisys â€“ DÃ©ploiement dâ€™un modÃ¨le de Machine Learning via API

## Contexte
**Futurisys** est une entreprise innovante souhaitant rendre ses modÃ¨les de machine learning
opÃ©rationnels et accessibles via une API performante.

Ce projet correspond Ã  un **Proof of Concept (POC)** visant Ã  dÃ©ployer un modÃ¨le de machine
learning en production en appliquant les bonnes pratiques dâ€™ingÃ©nierie logicielle: versionnage, tests, base de donnÃ©es et automatisation.


## Objectifs du projet
- DÃ©ployer un modÃ¨le de machine learning via une API REST
- Rendre le modÃ¨le accessible de maniÃ¨re fiable et documentÃ©e
- Mettre en place une architecture maintenable et Ã©volutive
- Appliquer un workflow Git professionnel
- PrÃ©parer une base solide pour un dÃ©ploiement en production


## PÃ©rimÃ¨tre fonctionnel
Le projet inclut:
- Une API dÃ©veloppÃ©e avec **FastAPI**
- Lâ€™exposition dâ€™un modÃ¨le de machine learning via des endpoints REST
- Une base de donnÃ©es **PostgreSQL** pour stocker les entrÃ©es/sorties du modÃ¨le
- Des tests unitaires et fonctionnels avec **Pytest**
- Un pipeline **CI/CD** pour automatiser les tests et le dÃ©ploiement
- Une documentation technique centralisÃ©e dans ce README

## ModÃ¨le de Machine Learning (ML)
### `ProblÃ©matique`
Le modÃ¨le vise Ã  rÃ©soudre un problÃ¨me de classification binaire :

- `0`: lâ€™employÃ© reste dans lâ€™entreprise
- `1`: lâ€™employÃ© prÃ©sente un risque de dÃ©part

Lâ€™objectif mÃ©tier est dâ€™anticiper le turnover afin de permettre aux Ã©quipes RH de prioriser des actions de rÃ©tention.

### `DonnÃ©es et features`
Le modÃ¨le sâ€™appuie sur un dataset RH prÃ©parÃ© et nettoyÃ© en amont contenant des:
- donnÃ©es professionnelles et contextuelles (poste, dÃ©partement, anciennetÃ©, etc.)
- variables comportementales et organisationnelles

Dataset final composÃ© de **32 features**:
```text
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 1470 entries, 0 to 1469
Data columns (total 32 columns)
```
Les prÃ©traitements incluent :
- le nettoyage et la normalisation des donnÃ©es brutes (3 bases distinctes brutes reÃ§ues) 
- le feature engineering: enrichissement des donnÃ©es
- le choix des variables non redondantes (corrÃ©lation infÃ©rieure Ã  70% entre les features numÃ©riques & les plus correlÃ©es avec la cible) 
- normalisation des variables numÃ©riques & encodage des variables catÃ©gorielles:
```python
transfo_colonnes = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), colonnes_quantitatives),
        ('cat', OneHotEncoder(handle_unknown='ignore', max_categories=15, sparse_output=False), colonnes_qualitatives), 
        ('ord', OrdinalEncoder(handle_unknown="use_encoded_value", unknown_value=-1), colonnes_ordinales)])
```
La table `employees_dataset` sert de rÃ©fÃ©rence documentaire du schÃ©ma attendu par le modÃ¨le.

### `Choix du modÃ¨le`

Le modÃ¨le retenu est un algorithme de gradient boosting (**XGBoost**) entraÃ®nÃ© avec des hyperparamÃ¨tres optimisÃ©s:
```python
# Les hyperparamÃ¨trs trouvÃ©s
Meilleurs paramÃ¨tres : {'classifier__colsample_bytree': 0.8, 'classifier__gamma': 1, 'classifier__learning_rate': 0.3, 'classifier__max_depth': 3, 'classifier__min_child_weight': 5, 'classifier__n_estimators': 400, 'classifier__reg_lambda': 1, 'classifier__subsample': 0.8}
```
Ce choix est justifiÃ© par:
- de bonnes performances sur des donnÃ©es tabulaires
- un compromis efficace entre prÃ©cision et capacitÃ© de gÃ©nÃ©ralisation
- un temps dâ€™infÃ©rence compatible avec une exposition via API

![image](Other\comp_modeles.PNG)

### `SÃ©rialisation et versionnage`

- Le modÃ¨le est sÃ©rialisÃ© au format `joblib`
- Une version du modÃ¨le est associÃ©e Ã  chaque prÃ©diction dans la table correspondante(`v1`)
- Les artefacts ML:
  - en **environnement local**, ils peuvent Ãªtre prÃ©sents pour les tests
  - en **production**, ils sont systÃ©matiquement tÃ©lÃ©chargÃ©s depuis un espace Hugging Face Hub dÃ©diÃ© au stockage des artefacts.

### `Performance et Ã©valuation du modÃ¨le`
- SÃ©paration du dataset en ensembles train / test
- Validation basÃ©e sur des mÃ©triques adaptÃ©es au contexte mÃ©tier:
  - **Recall (0.70)**: limiter les faux nÃ©gatifs (dÃ©parts non dÃ©tectÃ©s)
  - **F1-score (0.52 - validation croisÃ©e)**: Ã©quilibre entre prÃ©cision et rappel
  - **ROC-AUC (0.80 - validation croisÃ©e)**: capacitÃ© de discrimination globale du modÃ¨le

Le recall est volontairement privilÃ©giÃ© afin de maximiser la dÃ©tection des employÃ©s Ã  risque, mÃªme au prix de quelques faux positifs.

### `Limites`
- Le modÃ¨le fournit une probabilitÃ©, ***pas une dÃ©cision finale***
- Les prÃ©dictions doivent Ãªtre interprÃ©tÃ©es comme une aide Ã  la dÃ©cision
- Les performances dÃ©pendent fortement de la qualitÃ© et de lâ€™actualitÃ© des donnÃ©es RH
- Des biais peuvent exister si les donnÃ©es historiques sont dÃ©sÃ©quilibrÃ©es.

## CI/CD et DÃ©ploiement

Ce projet met en Å“uvre une approche CI/CD complÃ¨te, sÃ©parant:
- lâ€™intÃ©gration continue (**CI**): garantir la qualitÃ© du code
- le dÃ©ploiement continu (**CD**): rendre lâ€™API accessible publiquement

### `IntÃ©gration Continue (CI) â€“ GitHub Actions`

Ã€ chaque **push** ou **pull request** sur les branches de travail et vers **`develop`**, le pipeline CI exÃ©cute automatiquement:
- l'installation dâ€™un environnement Python 3.11
- l'installation des dÃ©pendances dÃ©finies dans le projet
- l'exÃ©cution des tests unitaires et fonctionnels

Lâ€™objectif est de garantir la stabilitÃ© de lâ€™API et dâ€™Ã©viter toute rÃ©gression.

### `DÃ©ploiement Continu (CD) â€“ Hugging Face Spaces`

Dans ce projet, Hugging Face est utilisÃ© comme plateforme de dÃ©monstration et de mise Ã  disposition de lâ€™API.

Le dÃ©ploiement repose sur un `Dockerfile`, qui dÃ©finit:
- lâ€™image Python utilisÃ©e (Python 3.11)
- lâ€™installation des dÃ©pendances
- le lancement de lâ€™API avec Uvicorn.

A noter que les ***fichiers binaires*** ne sont pas stockÃ©s dans le dÃ©pÃ´t GiHub principal pour les raisons suivantes:
- Hugging Face bloque les push Git contenant des fichiers binaires lourds
- Git nâ€™est pas conÃ§u pour versionner des artefacts ML volumineux.

Pour contourner la situation, dans le projet, les artefacts sont stockÃ©s dans un Space Hugging Face dÃ©diÃ©, sÃ©parÃ© du code. Lors du dÃ©marrage de lAPI:
- le code tÃ©lÃ©charge dynamiquement les artefacts via huggingface_hub
- lâ€™API peut dÃ©marrer mÃªme si les fichiers ne sont pas prÃ©sents localement.

### `Installation et configuration`

Les prÃ©requis:
- Python 3.11
- Poetry
- PostgreSQL (optionnel en local)
```git bash
git clone <repository_url>
cd futurisys_ml-api
poetry install
```
Les variables suivantes doivent Ãªtre dÃ©finies pour la connexion Ã  la base SQL:
- `DB_USER`
- `DB_PASSWORD`
- `DB_HOST`
- `DB_PORT`
- `DB_NAME`

Elles sont chargÃ©es via un fichier `.env` non versionnÃ©.

### `Lancer lâ€™API`

- **En local**: 
```python
uvicorn App.main:app --reload
```
Documentation interactive (Swagger UI) - http://127.0.0.1:8000/docs

- **En production (Hugging Face Spaces**):

  - API: https://diaure-futurisys-api-ml.hf.space
  - Swagger UI: https://diaure-futurisys-api-ml.hf.space/docs 
  
Le dÃ©ploiement permet de:
- visualiser les endpoints
- tester directement lâ€™endpoint `/predict`
- voir les schÃ©mas dâ€™entrÃ©e et de sortie.

### `Endpoint principal`
`POST /predict`

Cet endpoint reÃ§oit les caractÃ©ristiques dâ€™un employÃ© et retourne:

- une prÃ©diction lisible (`"Reste"` ou `"Part"`)
- la probabilitÃ© associÃ©e au dÃ©part

```json
{
  "Prediction": "Part",
  "Probabilite_depart": 0.795678996
}
```
Les donnÃ©es dâ€™entrÃ©e sont validÃ©es via **Pydantic** avec lâ€™appel du modÃ¨le.

### `Maintenance et mise Ã  jour du modÃ¨le`

Une mise Ã  jour du modÃ¨le est recommandÃ©e:
- pÃ©riodiquement (ex. tous les 6 Ã  12 mois)
- ou en cas de dÃ©rive des donnÃ©es.

Le processus inclut:
- la collecte de nouvelles donnÃ©es
- le rÃ©entraÃ®nement du modÃ¨le
- l'Ã©valuation des performances
- la validation mÃ©tier
- le dÃ©ploiement dâ€™une nouvelle version.

## Base de donnÃ©es et traÃ§abilitÃ© des prÃ©dictions
### `Objectifs`

Lâ€™intÃ©gration dâ€™une base de donnÃ©es PostgreSQL permet dâ€™inscrire le projet dans une logique MLOps et de rÃ©pondre Ã  plusieurs objectifs clÃ©s:
- assurer la traÃ§abilitÃ© complÃ¨te des prÃ©dictions du modÃ¨le
- conserver lâ€™historique des donnÃ©es dâ€™entrÃ©e utilisateur
- stocker les rÃ©sultats de prÃ©diction (label, probabilitÃ©, version du modÃ¨le)
- prÃ©parer une architecture compatible avec un dÃ©ploiement en production.

### `MÃ©thodologie utilisÃ©e`
- **PostgreSQL** a Ã©tÃ© retenu pour:
  - sa robustesse et sa fiabilitÃ©
  - sa compatibilitÃ© native avec SQLAlchemy
  - son usage courant en environnement professionnel

- **SQLAlchemy** est utilisÃ© comme couche dâ€™abstraction:
  - gestion centralisÃ©e de la connexion Ã  la base
  - cohÃ©rence entre le schÃ©ma Python et la base SQL

Les identifiants de connexion sont stockÃ©s dans des variables dâ€™environnement (`.env`) afin dâ€™Ã©viter toute exposition de secrets dans le dÃ©pÃ´t Git.

### `ModÃ©lisation de la base de donnÃ©es`
La base de donnÃ©es repose sur trois tables distinctes, chacune ayant un rÃ´le prÃ©cis.
1. `employees_dataset - Dataset de rÃ©fÃ©rence`
Il contient le dataset final nettoyÃ© et prÃ©parÃ© lors de l'entraÃ®nement du modÃ¨le en incluant l'ensemble des **32 features** du modÃ¨le. Il sert de:
  - rÃ©fÃ©rence de schÃ©ma
  - source de validation
  - base documentaire du modÃ¨le

C'est une table qui n'est jamais alimentÃ©e par l'utilisateur.

2. `inputs - EntrÃ©es utilisateur`
  - Enregistre chaque requÃªte utilisateur envoyÃ©e Ã  l'endpoint `/predict`
  - Contient exactement les features attendues par le modÃ¨le
  - Structure strictement alignÃ©e avec le schÃ©ma Pydantic(`EmployeeFeatures`)
  - Permet:
    - l'audit des predictions
    - l'analyse Ã  posteriori
    - la reproductibilitÃ© des rÃ©sultats.
```python
class Input(Base):
    __tablename__ = "inputs"

    id = Column(Integer, primary_key=True, index=True)
    genre = Column(String)
    statut_marital = Column(String)
    departement = Column(String)
    poste = Column(String)
```

3. `predictions - RÃ©sultats du modÃ¨le`
  - Continet:
    - le label de prÃ©diction
    - la probabilitÃ© associÃ©e
  - ReliÃ©e Ã  `inputs` via une clÃ© Ã©trangÃ¨re
  - Garantit une trÃ§abilitÃ© complÃ¨te.
```python
class Predictions(Base):
    __tablename__ = "predictions"
    id = Column(Integer, primary_key=True, index=True)
    input_id = Column(Integer, ForeignKey("inputs.id"))

    prediction_label = Column(String)
    prediction_proba = Column(Float)
    model_version = Column(String)
```

### `Interaction API <> Base de donnÃ©es`
Lors dâ€™un appel Ã  lâ€™endpoint `POST /predict`:
- les donnÃ©es utilisateur sont validÃ©es via **Pydantic**
- les entrÃ©es sont enregistrÃ©es dans la table **inputs**
- le modÃ¨le est exÃ©cutÃ©
- la prÃ©diction est enregistrÃ©e dans la table **predictions**
- la rÃ©ponse est retournÃ©e Ã  lâ€™utilisateur.

## Tests et QualitÃ©

### `Objectifs des tests`

Les tests ont Ã©tÃ© conÃ§us pour:
- valider le bon fonctionnement des composants critiques (chargement du modÃ¨le, validation des donnÃ©es, etc)
- garantir que lâ€™API rÃ©pond correctement dans des scÃ©narios rÃ©els
- dÃ©tecter rapidement les rÃ©gressions lors du dÃ©veloppement
- assurer la reproductibilitÃ© des rÃ©sultats
- fournir des indicateurs de qualitÃ© (couverture de tests)

Lâ€™ensemble des tests est exÃ©cutÃ© automatiquement dans le pipeline CI Ã  chaque push ou pull request.

### `Types de tests exÃ©cutÃ©s`
- **Tests unitaires** qui sont des tests rapides qui permettent de dÃ©tecter immÃ©diatement les erreurs de logique. Ils se concentrent sur les composants isolÃ©s du projet comme:
  - la vÃ©rification du chargement du modÃ¨le et du mapping des classes sans levÃ©e d'erreurs (`model_loading.py`)
  - la validation des donnÃ©es via Pydantic et test de l'endpoint de bout en bout(`test_api.py`)

- **Tests fonctionnels** qui Ã©valuent lâ€™application dans son ensemble en simulant un usage rÃ©el de lâ€™API et garantissant son bon comportement en production:
  - contrÃ´le du fonctionnement de l'API en mode CI lorsque la base est dÃ©sactivÃ©e CI (`test_db_disabled.py`)
  - test tout le pipeline de prÃ©diction (`test_predict_endpoint.py`)
  - test spÃ©cifique de l'endpoint `/predict` et vÃ©rification de la cohÃ©rence de la rÃ©ponse.

**ExÃ©cution locale** des tests:
```python
poetry run pytest
poetry  run pytest tests.units
poetry  run pytest tests.fonctionnel
```
### `Rapport de couverture`
GÃ©nÃ©rÃ© automatiquement dans GitHub Actions, c'est un apport qui mesure la proportion de code Ã©xÃ©cutÃ©e par les tests en indiquant:
- quelles lignes ont Ã©tÃ© exÃ©cutÃ©es
- quelles lignes ne l'ont pas Ã©tÃ©
- le pourcentage global de couverture.

Il a pour rÃ´le:
- d'Ã©valuer la qualitÃ© de la suite de tests
- d'identifier les zones non testÃ©es
- de rÃ©duire les risques de rÃ©gression
- de garantir la fiabilitÃ© du code avant dÃ©ploiement
- de donner un indicateur objectif de maturitÃ© logicielle.

Dans ce projet, le pipeline CI dÃ©sactive la base de donnÃ©es, ainsi il n'y a pas de test sur:
- la connexion DB
- les insertions
- les interactions **SQLALCHEMY**.
Donc toutes les lignes liÃ©es Ã  la DB ne sont pas exÃ©cutÃ©es, d'oÃ¹ il peut Ãªtre observÃ© une `couverture plus faible GitHub Actions vs local`.
```text
============================== local tests coverage =====================================

Name              Stmts   Miss  Cover   Missing
-----------------------------------------------
App\database.py      25      4    84%   9-10, 35-36
App\main.py          10      1    90%   13
App\model.py         48      2    96%   55-56
App\predict.py       52      9    83%   15-19, 62, 77-79
App\schemas.py       32      0   100%
-----------------------------------------------
TOTAL               167     16    90%

========================== GitHub Actions tests coverage ================================
Name              Stmts   Miss  Cover   Missing
-----------------------------------------------
App/database.py      25     10    60%   9-10, 23-32
App/main.py          10     10     0%   1-20
App/model.py         48      2    96%   55-56
App/predict.py       52     28    46%   15-19, 49-85
App/schemas.py       32      0   100%
-----------------------------------------------
TOTAL               167     50    70%
```

## Stack technique
- **Langage**: Python
- **API**: FastAPI
- **Machine Learning**: scikit-learn
- **Base de donnÃ©es**: PostgreSQL
- **Tests**: Pytest, pytest-cov
- **CI/CD**: GitHub Actions, Hugging Face
- **Versionnage**: Git / GitHub

## Architecture du projet

Lâ€™architecture du projet repose sur une sÃ©paration claire des responsabilitÃ©s afin de garantir la lisibilitÃ©, la maintenabilitÃ© et lâ€™Ã©volutivitÃ© de lâ€™application.

### `Vue dâ€™ensemble`

                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚        Utilisateur           â”‚
                          â”‚         (Client)             â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚  RequÃªte POST /predict
                                          â–¼
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚        API FastAPI           â”‚
                          â”‚         (main.py)            â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                          â–¼
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚        Module de prÃ©diction      â”‚
                          â”‚            (predict.py)          â”‚
                          â”‚  - Chargement du modÃ¨le HF Hub   â”‚
                          â”‚  - Validation                    â”‚
                          â”‚  - PrÃ©diction                    â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                          â–¼
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚        Base de donnÃ©es PostgreSQL      â”‚
                          â”‚   (inputs / predictions / dataset)     â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚      CI/CD â€“ GitHub Actions            â”‚
                          â”‚  - Tests unitaires                     â”‚
                          â”‚  - Tests fonctionnels                  â”‚
                          â”‚  - Rapport de couverture               â”‚
                          â”‚  - DÃ©ploiement sur HF Space            â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


### `Description du flux`

1. Un utilisateur envoie une requÃªte `POST /predict` Ã  lâ€™API

2. Lâ€™API FastAPI agit comme point dâ€™entrÃ©e:
   - validation des donnÃ©es via **Pydantic**
   - orchestration du traitement

3. Le module de prÃ©diction:
   - charge dynamiquement le modÃ¨le ML depuis **Hugging Face Hub**
   - gÃ©nÃ¨re la prÃ©diction et la probabilitÃ© associÃ©e

4. Les donnÃ©es dâ€™entrÃ©e et les rÃ©sultats sont enregistrÃ©s dans une base **PostgreSQL** afin dâ€™assurer la traÃ§abilitÃ©

5. La rÃ©ponse est retournÃ©e au client sous forme JSON

6. Le cycle de dÃ©veloppement, de test et de dÃ©ploiement est automatisÃ© via un pipeline **CI/CD GitHub Actions** avec dÃ©ploiement sur **Hugging Face Spaces**.

Cette architecture permet une exposition fiable du modÃ¨le de Machine Learning, tout en respectant les bonnes pratiques MLOps et dâ€™ingÃ©nierie logicielle.


## Structure du projet
```text
futurisys_ml-api/
â”œâ”€â”€ github/workflows
â”‚   â”œâ”€â”€ ci.yml       # Description des Ã©vÃ¨nement dÃ©clenchants des tests
â”œâ”€â”€ app/             # Code applicatif principal
â”‚   â”œâ”€â”€ database.py  # Point de connexion Ã  la base PostgreSQL
â”‚   â”œâ”€â”€ main.py      # Point dâ€™entrÃ©e de lâ€™API
â”‚   â”œâ”€â”€ model.py     # DÃ©finition des tables de la database
â”‚   â”œâ”€â”€ predict.py   # Application du modÃ¨le
â”‚   â”œâ”€â”€ schemas.py   # Validation des donnÃ©es (Pydantic)
â”‚   â”€â”€ model/                       # Elements du modÃ¨le
â”‚   â”œâ”€â”€ mapping_classes.json        # Correspondances des classes
â”‚   â”œâ”€â”€ modele_final_xgb.joblib     # ModÃ¨le final avec hyperparamÃ¨tres
|
â”œâ”€â”€ scripts/                 # Scripts bd (BD, donnÃ©es)
â”‚   â”œâ”€â”€ create_tables.py     # CrÃ©aton des tables dÃ©finies dans model.py
â”‚   â”œâ”€â”€ dataset_final.csv    # Data final
â”‚   â”œâ”€â”€ insert_dataset.py    # Code chargement de la table dataset_final
|
â”œâ”€â”€ tests/                      # Tests unitaires, fonctionnels
â”‚   â”œâ”€â”€ test_sanity.py           # Test de vÃ©rification rapide
â”‚   â”œâ”€â”€ test_api.py              # Tests API supplÃ©mentaires
â”‚   â”œâ”€â”€ test_sanity.py           # Test de vÃ©rification rapide
|
â”‚   â”€â”€ fonctionnel/             # Tests fonctionnels
â”‚   â”œâ”€â”€ sample_payload.py        # Test automatisÃ© de l'API via Pytest
â”‚   â”œâ”€â”€ test_api.py              # Tests API supplÃ©mentaires
â”‚   â”œâ”€â”€ test_sanity.py           # Test de vÃ©rification rapide
|
â”‚   â”€â”€ units/                   # Tests unitaires
â”‚   â”œâ”€â”€ test_model_loading.py    # Test automatisÃ© de l'API via Pytest
|
â”œâ”€â”€ .env             # Stockage des variables sensibles et de configuration
â”œâ”€â”€ .gitignore       # Nettoyage du dÃ©pÃ´t
â”œâ”€â”€ Dockerfile       # Reproduction du dÃ©pÃ´t
â”œâ”€â”€ poetry.lock      # Nettoyage du dÃ©pÃ´t
â”œâ”€â”€ pyproject.toml   # Librairies dÃ©pendances ML
â”œâ”€â”€ README.md        # PrÃ©sentation du projet
â””â”€â”€ requirements.txt # Librairies dÃ©pendances API
```
